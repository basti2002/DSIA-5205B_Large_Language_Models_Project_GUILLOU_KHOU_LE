{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMaNrubfx_Al"
      },
      "source": [
        "# Bastien GUILLOU, Ryan KHOU and Van-Minh Christophe LE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYgBkm-6x_Am"
      },
      "source": [
        "## Project objective:\n",
        "\n",
        "This notebook retraces the development and fine-tuning process of a large language model (LLM) based on GPT-2, specially adapted to meet a precise daily need: automatic correction of spelling errors in texts. This fine-tuned model aims to improve the accuracy and effectiveness of French grammar correction in various contexts of daily communication. This project builds on the knowledge gained from the pre-training and fine-tuning sessions of Chapters 5, 6, and 7 and the Labs 6-7 to create a functional prototype that demonstrates how fine-instructiontuning can dramatically improve the model’s ability to follow user\n",
        "commands and prompts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqXawOIpL2uI"
      },
      "source": [
        "# Phase 1: Environment Setup & Base Model Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTR3aKe_x_An"
      },
      "source": [
        "A pre-trained GPT-2 model with its hyper parameters is initialized and loaded, running on a CUDA device if available for more computational speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQI9NBu-L2uK",
        "outputId": "5baaa20e-4508-4610-8cc0-9dbfdabc4980"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 33.9kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 649kiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 37.2kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [08:24<00:00, 2.81MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 6.17MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 562kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 380kiB/s]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_labs import GPTModel, load_weights_into_gpt\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAaLbE-dx_Ao"
      },
      "source": [
        "Check that the model is loaded correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmC_8rwbL2uM",
        "outputId": "b3e931ca-b863-41fa-b2dd-35258de4478f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 1024)\n",
            "  (pos_emb): Embedding(1024, 1024)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (12): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (13): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (14): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (15): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (16): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (17): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (18): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (19): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (20): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (21): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (22): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (23): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vfK0WcYL2uM"
      },
      "source": [
        "# Phase 2: Instruction Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzZkBzeQx_Ap"
      },
      "source": [
        "We load a spell check dataset from Hugging Face, create instruction pairs to train our model from the data, and save those pairs in a JSON file for fine-tuned the model later. Finally, we display a sample of the pairs to check their format and content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446,
          "referenced_widgets": [
            "ab69f6830afd49618b0eb933c0596e7d",
            "a6812859e84f428d8b26f06c48ff6068",
            "2ae846523fae43cfa21d1d4bd27a1698",
            "31a172b0f05447cd9be9a3a5222b6b15",
            "65722aa38d734a9faecb5eaadffedcb0",
            "a0c84288381f4fcc9b0c3172b224ae0e",
            "624d1ae88acf45338fb2f7046311e7f2",
            "474d3c71371f4885a8adcf43e1ea8cd5",
            "aeb1e90a77b54148896369d3f5d5681f",
            "e2fde490b0bc4e9bbf0af7f35ce26236",
            "12e5a69fe6f540fd8c11214090bca30a",
            "f466fd37e47f463b8589941ed24798ac",
            "2f600a464b204be3abf42b523b71ba97",
            "639b7eeb04e74fb096a6b34fdb55ed5b",
            "6a36562da4a54569b0ce83def5a8cd41",
            "49b440e5088e4d0b810471309cd4e252",
            "8de2dc7bef5e46b89549e9ccc5dcec28",
            "d2a7f9304300492686a8528916601d4f",
            "ad4b32e67efb4638a6f83842f39b03e6",
            "8e8f5c95fac64bdc8e9658e96e717850",
            "47023f7309be4c67bac489ec3cc59b45",
            "6d4e5ba99abb4e73be7ba2742fa0f8e4",
            "1dada07c92974386b0abbf77eae5bf6a",
            "ca78407d76134a1e93880404f77a9594",
            "84b11864eea44c9cad4e5994c03f748f",
            "9029f7e1bbcc4db5ad883353320375ef",
            "11fbb6766070433abcebf79b01e39507",
            "2196a9b537c84528aafc6b195ea2a697",
            "094c09b681784af69ca3ef490be44896",
            "5656667ec2394eb89b3eb3016b16f536",
            "6cb8e5ae22e94310b8a87fe9f99c2d78",
            "28462e3252de40caa649850f5bc2c8fa",
            "a9fbab402b4e45b5b442bf877fd90cf7"
          ]
        },
        "id": "SkouhyVYL2uN",
        "outputId": "3c7be7a6-b087-468f-da73-0ba3c2f9d80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"instruction\": \"Corrigez le texte suivant.\",\n",
            "        \"input\": \"grammaire: 145 mille lénages vont en bénéficier.\",\n",
            "        \"output\": \"145 mille ménages vont en bénéficier.\"\n",
            "    },\n",
            "    {\n",
            "        \"instruction\": \"Corrigez le texte suivant.\",\n",
            "        \"input\": \"grammaire: 145 mille ménages vont enbénéficier.\",\n",
            "        \"output\": \"145 mille ménages vont en bénéficier.\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import json\n",
        "\n",
        "def create_instruction_pairs(entries):\n",
        "    instruction_data = []\n",
        "    for entry in entries:\n",
        "\n",
        "        # Directly use the texts without encoding conversion\n",
        "        input_text = entry['input']\n",
        "        output_text = entry['target']\n",
        "\n",
        "        # Prepare data for grammatical correction\n",
        "        instruction_data.append({\n",
        "            \"instruction\": \"Corrigez le texte suivant.\",\n",
        "            \"input\": input_text,\n",
        "            \"output\": output_text\n",
        "        })\n",
        "\n",
        "    return instruction_data\n",
        "\n",
        "def save_data_to_json(instruction_data, file_path=\"correction-data.json\"):\n",
        "    # Save the instruction pairs\n",
        "    with open(file_path, \"w\", encoding='utf8') as file:\n",
        "        json.dump(instruction_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "dataset = load_dataset(\"fdemelo/spelling-correction-french-news\")\n",
        "\n",
        "# Creation of the instruction pairs\n",
        "instruction_pairs = create_instruction_pairs(dataset['train'])\n",
        "\n",
        "save_data_to_json(instruction_pairs)\n",
        "\n",
        "# Display of a sample for verification\n",
        "print(json.dumps(instruction_pairs[:2], ensure_ascii=False, indent=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMCptE6Fx_Aq"
      },
      "source": [
        "Random typographical errors are introduced in the texts to increase the data set, while preserving the prefix \"grammar:\". This method generates several variants of a text to improve the robustness of the model during training. The augmented data is then recorded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f-lVJOScIEV",
        "outputId": "a3f7d72a-3217-49ba-eaca-59dcc703c1f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Augmented data saved successfully.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def introduce_errors(text):\n",
        "    # Initialize constants and random operations\n",
        "    prefix = \"grammaire: \"\n",
        "    prefix_len = len(prefix)\n",
        "    operations = ['delete', 'swap', 'insert']\n",
        "    characters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    new_text = list(text)\n",
        "    num_errors = random.randint(1, 2)\n",
        "\n",
        "    # Apply random grammatical errors to text\n",
        "    for _ in range(num_errors):\n",
        "        operation = random.choice(operations)\n",
        "        index = random.randint(prefix_len, len(new_text) - 2)\n",
        "\n",
        "        if operation == 'delete' and len(new_text) > prefix_len:\n",
        "            new_text.pop(index)\n",
        "        elif operation == 'swap' and index + 1 < len(new_text):\n",
        "            new_text[index], new_text[index + 1] = new_text[index + 1], new_text[index]\n",
        "        elif operation == 'insert':\n",
        "            new_text.insert(index, random.choice(characters))\n",
        "\n",
        "    return ''.join(new_text)\n",
        "\n",
        "def augment_data(data, num_variants):\n",
        "    # Generate multiple variants of the data with introduced errors\n",
        "    augmented_data = []\n",
        "    for item in data:\n",
        "        original_input = item['input']\n",
        "        augmented_data.append(item)\n",
        "        for _ in range(1, num_variants):\n",
        "            augmented_input = introduce_errors(original_input)\n",
        "            augmented_item = {\n",
        "                'instruction': item['instruction'],\n",
        "                'input': augmented_input,\n",
        "                'output': item['output']\n",
        "            }\n",
        "            augmented_data.append(augmented_item)\n",
        "    return augmented_data\n",
        "\n",
        "# Load original data\n",
        "with open('correction-data.json', 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Augment the data and create multiple variants of the sentence\n",
        "augmented_data = augment_data(data, num_variants=5)\n",
        "\n",
        "# Save the augmented data\n",
        "with open('augmented-correction-data.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(augmented_data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Augmented data saved successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gu5eOR1x_Aq"
      },
      "source": [
        "We check the correct creation of our dataset increased by the number of existing intructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fz9zzRfL2uO",
        "outputId": "67b6bfa0-0876-43b5-94d1-c8852df97522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 245560\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "  # Check if file exists, if not, download from URL and write to local file\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf8\") as file:\n",
        "            file.write(text_data)\n",
        "    # Try loading the file as JSON, handle exceptions for encoding issues\n",
        "    try:\n",
        "        with open(file_path, \"r\", encoding=\"utf8\") as file:\n",
        "            data = json.load(file)\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error reading {file_path}: {e}\")\n",
        "        data = None\n",
        "    return data\n",
        "\n",
        "file_path = \"augmented-correction-data.json\"\n",
        "url = \"\"\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "# Output the number of entries or an error message\n",
        "if data:\n",
        "    print(\"Number of entries:\", len(data))\n",
        "else:\n",
        "    print(\"Failed to load data due to encoding issues.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "413Qps0hx_Ar"
      },
      "source": [
        "Prepare the data batches for model training by adding an end of text token, adjusting sequence length to level out the batch, and managing the non-attention masks for completed sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VgnA2IOoL2uO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF0EKkL5x_As"
      },
      "source": [
        "We prepare and tokenize the training data for our model, formatting with the Alpaca prompt style the entries and the associated responses for each instruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QheephAQL2uP"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xD5rgK-HL2uQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC8oQ0aux_At"
      },
      "source": [
        "We load our instruction dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BDJ5WA8-L2uQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "\n",
        "from functools import partial\n",
        "import tiktoken\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)\n",
        "\n",
        "batch_size = 8\n",
        "num_workers = 0\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdDrP7rjL2uQ"
      },
      "source": [
        "# Phase 3: Instruction Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjSa5njQx_At"
      },
      "source": [
        "Now we need to creat all the function to evaluate our model and monitor its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoApV8EWx_At"
      },
      "source": [
        "A function is used to evaluate the model’s performance on the training and validation data sets, calculating and returning losses for each set in order to adjust and improve the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bKvrK4ecL2uR"
      },
      "outputs": [],
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_labs import (\n",
        "    calc_loss_loader,\n",
        "    generate,\n",
        "    GPTModel,\n",
        "    load_weights_into_gpt,\n",
        "    text_to_token_ids,\n",
        "    train_model_simple,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOjkS7fhx_Au"
      },
      "source": [
        "The loss for a batch of data is calculated by comparing the predicted outputs from the model with the true target values, using the cross entropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "raxsDgGSL2uR"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo5X-464x_Au"
      },
      "source": [
        "Reusing a function generates and displays an example of text from an initial context using a pre-trained template."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "r-AwN6JLL2uR"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsDG3IPPx_Av"
      },
      "source": [
        "The learning function given in previous Lab is adapted to train a model using training and validation data, adjusting the learning rate and implementing a loss of validation based early stop to prevent overlearning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "u2Nj22VCL2uR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer, patience=5):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    # Scheduler for learning rate adjustment\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "                # Adjust learning rate based on the validation loss\n",
        "                scheduler.step(val_loss)\n",
        "\n",
        "                # Check for early stopping\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    if epochs_no_improve >= patience:\n",
        "                        print(f'No improvement for {patience} evaluations, adjusting learning rate.')\n",
        "                        break  # Break out of the loop, go to the next epoch\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8zUpBcx_Av"
      },
      "source": [
        "Now we can train our model and print its losss function on training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hzZcRWClL2uS",
        "outputId": "79717f8c-a983-4dfe-bcdb-84ba575fed97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Training loss: 3.970228910446167\n",
            "Initial Validation loss: 4.199329805374146\n",
            "Ep 1 (Step 000000): Train loss 3.326, Val loss 3.592\n",
            "Ep 1 (Step 000005): Train loss 2.268, Val loss 2.500\n",
            "Ep 1 (Step 000010): Train loss 2.099, Val loss 2.212\n",
            "Ep 1 (Step 000015): Train loss 1.988, Val loss 2.144\n",
            "Ep 1 (Step 000020): Train loss 1.887, Val loss 2.105\n",
            "Ep 1 (Step 000025): Train loss 1.959, Val loss 2.101\n",
            "Ep 1 (Step 000030): Train loss 1.922, Val loss 2.074\n",
            "Ep 1 (Step 000035): Train loss 1.873, Val loss 2.062\n",
            "Ep 1 (Step 000040): Train loss 1.855, Val loss 2.057\n",
            "Ep 1 (Step 000045): Train loss 1.894, Val loss 2.061\n",
            "Ep 1 (Step 000050): Train loss 1.735, Val loss 2.081\n",
            "Ep 1 (Step 000055): Train loss 1.801, Val loss 2.069\n",
            "Ep 1 (Step 000060): Train loss 1.807, Val loss 2.046\n",
            "Ep 1 (Step 000065): Train loss 1.837, Val loss 2.030\n",
            "Ep 1 (Step 000070): Train loss 1.770, Val loss 2.020\n",
            "Ep 1 (Step 000075): Train loss 1.820, Val loss 2.008\n",
            "Ep 1 (Step 000080): Train loss 1.802, Val loss 1.998\n",
            "Ep 1 (Step 000085): Train loss 1.796, Val loss 1.981\n",
            "Ep 1 (Step 000090): Train loss 1.823, Val loss 1.977\n",
            "Ep 1 (Step 000095): Train loss 1.720, Val loss 1.965\n",
            "Ep 1 (Step 000100): Train loss 1.734, Val loss 1.966\n",
            "Ep 1 (Step 000105): Train loss 1.806, Val loss 1.973\n",
            "Ep 1 (Step 000110): Train loss 1.761, Val loss 1.965\n",
            "Ep 1 (Step 000115): Train loss 1.767, Val loss 1.952\n",
            "Ep 1 (Step 000120): Train loss 1.787, Val loss 1.939\n",
            "Ep 1 (Step 000125): Train loss 1.686, Val loss 1.927\n",
            "Ep 1 (Step 000130): Train loss 1.757, Val loss 1.925\n",
            "Ep 1 (Step 000135): Train loss 1.829, Val loss 1.918\n",
            "Ep 1 (Step 000140): Train loss 1.685, Val loss 1.908\n",
            "Ep 1 (Step 000145): Train loss 1.716, Val loss 1.907\n",
            "Ep 1 (Step 000150): Train loss 1.853, Val loss 1.905\n",
            "Ep 1 (Step 000155): Train loss 1.843, Val loss 1.900\n",
            "Ep 1 (Step 000160): Train loss 1.735, Val loss 1.898\n",
            "Ep 1 (Step 000165): Train loss 1.801, Val loss 1.904\n",
            "Ep 1 (Step 000170): Train loss 1.741, Val loss 1.896\n",
            "Ep 1 (Step 000175): Train loss 1.767, Val loss 1.889\n",
            "Ep 1 (Step 000180): Train loss 1.701, Val loss 1.872\n",
            "Ep 1 (Step 000185): Train loss 1.665, Val loss 1.866\n",
            "Ep 1 (Step 000190): Train loss 1.753, Val loss 1.851\n",
            "Ep 1 (Step 000195): Train loss 1.779, Val loss 1.860\n",
            "Ep 1 (Step 000200): Train loss 1.756, Val loss 1.858\n",
            "Ep 1 (Step 000205): Train loss 1.685, Val loss 1.853\n",
            "Ep 1 (Step 000210): Train loss 1.685, Val loss 1.851\n",
            "Ep 1 (Step 000215): Train loss 1.719, Val loss 1.845\n",
            "Ep 1 (Step 000220): Train loss 1.716, Val loss 1.859\n",
            "Ep 1 (Step 000225): Train loss 1.749, Val loss 1.869\n",
            "Ep 1 (Step 000230): Train loss 1.726, Val loss 1.859\n",
            "Ep 1 (Step 000235): Train loss 1.715, Val loss 1.859\n",
            "No improvement for 4 evaluations, adjusting learning rate.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrigez le texte suivant.  ### Input: grammaire: dUj cercle vicieux ui n4 semblec pas prendre fin ecette année.  ### Response: DU cercle vicieux qui n’a semble cette année.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction:\n",
            "Ep 2 (Step 000240): Train loss 1.694, Val loss 1.858\n",
            "No improvement for 4 evaluations, adjusting learning rate.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrigez le texte suivant.  ### Input: grammaire: dUj cercle vicieux ui n4 semblec pas prendre fin ecette année.  ### Response: Dans le cercle vicieux qui n'a semblece pas prendre fin de cette année.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the\n",
            "Ep 3 (Step 000245): Train loss 1.683, Val loss 1.842\n",
            "Ep 3 (Step 000250): Train loss 1.657, Val loss 1.855\n",
            "Ep 3 (Step 000255): Train loss 1.715, Val loss 1.863\n",
            "Ep 3 (Step 000260): Train loss 1.749, Val loss 1.862\n",
            "Ep 3 (Step 000265): Train loss 1.697, Val loss 1.850\n",
            "No improvement for 4 evaluations, adjusting learning rate.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrigez le texte suivant.  ### Input: grammaire: dUj cercle vicieux ui n4 semblec pas prendre fin ecette année.  ### Response: D’uj cercle vicieux qui n’a semble cette année.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ###\n",
            "Ep 4 (Step 000270): Train loss 1.664, Val loss 1.845\n",
            "No improvement for 4 evaluations, adjusting learning rate.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrigez le texte suivant.  ### Input: grammaire: dUj cercle vicieux ui n4 semblec pas prendre fin ecette année.  ### Response: D’uj cercle vicieux qui n’a semble cette année.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ###\n",
            "Ep 5 (Step 000275): Train loss 1.752, Val loss 1.837\n",
            "Ep 5 (Step 000280): Train loss 1.643, Val loss 1.849\n",
            "Ep 5 (Step 000285): Train loss 1.634, Val loss 1.844\n",
            "Ep 5 (Step 000290): Train loss 1.641, Val loss 1.820\n",
            "Ep 5 (Step 000295): Train loss 1.659, Val loss 1.815\n",
            "Ep 5 (Step 000300): Train loss 1.646, Val loss 1.814\n",
            "Ep 5 (Step 000305): Train loss 1.639, Val loss 1.814\n",
            "Ep 5 (Step 000310): Train loss 1.721, Val loss 1.819\n",
            "Ep 5 (Step 000315): Train loss 1.603, Val loss 1.812\n",
            "Ep 5 (Step 000320): Train loss 1.722, Val loss 1.815\n",
            "Ep 5 (Step 000325): Train loss 1.662, Val loss 1.823\n",
            "Ep 5 (Step 000330): Train loss 1.658, Val loss 1.821\n",
            "Ep 5 (Step 000335): Train loss 1.689, Val loss 1.816\n",
            "No improvement for 4 evaluations, adjusting learning rate.\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Corrigez le texte suivant.  ### Input: grammaire: dUj cercle vicieux ui n4 semblec pas prendre fin ecette année.  ### Response: D’un cercle vicieux qui n’a semble cette année.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ###\n",
            "Training completed in 10.91 minutes.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Model saved as saved_models/gpt2-medium355M-sft.pth\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from previous_labs import calc_loss_loader, plot_losses\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Définir les paramètres initiaux\n",
        "num_epochs = 5\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "eval_freq = 5\n",
        "eval_iter = 5\n",
        "patience = 4 # for early stopping\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Enregistrer les pertes initiales\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Initial Training loss: {train_loss}\")\n",
        "print(f\"Initial Validation loss: {val_loss}\")\n",
        "\n",
        "# Boucle d'entraînement avec early stopping et suivi de la perte de validation\n",
        "start_time = time.time()\n",
        "\n",
        "# Adapter la fonction d'entraînement avec early stopping\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=eval_freq, eval_iter=eval_iter,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer, patience=patience\n",
        ")\n",
        "\n",
        "# Calculer la durée d'entraînement\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n",
        "\n",
        "# Afficher les pertes sur les graphiques\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(\n",
        "    epochs_tensor,\n",
        "    tokens_seen,\n",
        "    train_losses,\n",
        "    val_losses\n",
        ")\n",
        "print(50*\"-\")\n",
        "\n",
        "# Ensure the model directory exists or create it\n",
        "model_directory = 'saved_models'\n",
        "os.makedirs(model_directory, exist_ok=True)\n",
        "file_name = os.path.join(model_directory, f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\")\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP8vcxqOx_Av"
      },
      "source": [
        "# Phase 4: Evaluation & Iterative Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQY7SKq-x_Aw"
      },
      "source": [
        "We test our model on a set of test data based on instructions formatted in the Alpaca style, and display both the expected correct answers and those generated by the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jcg1NXF1L2uS",
        "outputId": "011cd59e-ffd8-4648-fc9e-dbfe746a7976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu co§me un titre cross-lpay PS3/Vita, lSy 4a peutt-être souffert de ce développemteknt conoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu co§me un titre cross-play PS3/Vita, la Sy 4a peut-être souffert de ce développement conoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu co§me un titre cross-lpay PS3/Via, lSy 4a peutt-être souffert de ce développmeent conoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu co§me un titre cross-play PS3/Via, la Sy 4a peut-être souffert de ce développeent conoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu cou§me un titre cross-lpay PS3/Vita, lSy 4a peutt-être souffefrt de ce développement conoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu coupe un titre cross-play PS3/Vita, la Sy 4a peut-être souffre de ce développement conoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu co§me un titre cross-lpay PS3/Vita, lSy 4a peutt-être sofufert de ce développement conoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu co§me un titre cross-play PS3/Vita, la Sy 4a peut-être soffert de ce développement conoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu comme un titre cross-play PS3/Bita, Sly 4 a peut-être souffert de ce développemnet conjoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu comme un titre cross-play PS3/Bita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu comme un titre cross-ply PS3/Bita, Sly 4 a peut-être souffert de ce développemnet conjoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu comme un titre cross-play PS3/Bita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu comme un titre cross-plday PS3/Bita, Sly 4 a peut-être souffert de ce développemnet conjoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu comme un titre cross-play PS3/Bita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu comme un titre cross-play PS3/Bita, Sly 4 a peut-être osuffert de ce développemnet conjoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu comme un titre cross-play PS3/Bita, Sly 4 a peut-être soutenir de ce développement conjoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu comme un titre cross-play PS3/Bita, Sly 4 a peuct-tre souffert de ce développemnet conjoint.\n",
            "\n",
            "Correct response:\n",
            ">> Prévu comme un titre cross-play PS3/Vita, Sly 4 a peut-être souffert de ce développement conjoint.\n",
            "\n",
            "Model response:\n",
            ">> Prévu comme un titre cross-play PS3/Bita, Sly 4 a peu-tre souffert de ce développement conjoint.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu aprs 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 ã finalement eeu lieu ce mercredi 23 aotû à 14  30 su le pôke ud lunairee.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 ã finalement eu lieu ce mercredi 23 aotût à 14 à 30 su le pôle du lunaire de.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu aprs 18 heures, l’alunissage de rla fusée indienne Chandrayaan-3 ã finalement eeu lieu ce mercredi 23 aotû à 14  30 su le pôke ud lunairee.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 ã finalement eu lieu ce mercredi 23 aotût à 14 à 30 su le pôle du lunaire de.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu aprs 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 ã finalement eeu lieu ce mrecredi 23 aotû à 14  30 su le pôke ud lunairee.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 ã finalement eu lieu ce mrecrède 23 aotût à 14 à 30 su le pôle du lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu aprs 18 heures, la’lunissage de la fusée indienne Chandrayaan-3 ã finalement eeu lieu ce mercredi 23 aotû à 14  30 su le pôke ud lunairee.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heures, la lune de la fusée indienne Chandrayaan-3 ã finalement eu lieu ce mercredi 23 aotût à 14 à 30 su le pôle du lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu aprs 18 heures, l’amlunissage de la fusée indienne Chandrayaan-3 ã finalement eeu lieu ce mercredi 23 atotû à 14  30 su le pôke ud lunairee.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heures, l’amateur de la fusée indienne Chandrayaan-3 ã finalement eu lieu ce mercredi 23 atotû à 14  30 sur le pôle du lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu après 18 heuress, ’alunissage de ala fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 aotût àà 14 b 30 susr le pôle SSud lunaire.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heure, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 aotût à 14 b 30 sur le pôle Sud le lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu après 18 heuress, ’alunissage de ala fusée indienn eChandrayaan-3 a finalement eu lieu ce mercredi 23 aotût àà 14 b 30 susr le pôle SSud lunaire.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heure, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 aotût à 14 b 30 sur le pôle Sud le lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu après 18 heuress, ’alunissage de ala fusée indienne Chandrayaan-3 a finalement eu lieu ce fmercredi 23 aotût àà 14 b 30 susr le pôle SSud lunaire.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heure, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce fmercredi 23 aotût à 14 b 30 sur le pôle Sud le lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu après 18 heuress, ’alunissage d eala fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 aotût àà 14 b 30 susr le pôle SSud lunaire.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heure, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 aotût à 14 b 30 sur le pôle Sud le lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévue peu après 18 heuress, ’alunissage de ala fusée indienne Chandrayaan-3 a finailement eu lieu ec mercredi 23 aotût àà 14 b 30 susr le pôle SSud lunaire.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévue peu après 18 heure, l’alunissage de la fusée indienne Chandrayaan-3 a finailement de lieu ec mercredi 23 aotût à 14 b 30 sur le pôle Sud lunaire.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Prévu pei aprsè 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu ieu ce mercred9 23 août àà 14  30 sur le plôe Sud lunaire.\n",
            "\n",
            "Correct response:\n",
            ">> Prévue peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu lieu ce mercredi 23 août à 14 h 30 sur le pôle Sud lunaire.\n",
            "\n",
            "Model response:\n",
            ">> Prévu peu après 18 heures, l’alunissage de la fusée indienne Chandrayaan-3 a finalement eu ieu ce mercredi 23 août à 14 à 30 sur le plôe Sud lunaire.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model.eval();\n",
        "\n",
        "for entry in test_data[:20]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJZyrSNvx_Aw"
      },
      "source": [
        "We test our model on custom instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65i3nLDupUtV",
        "outputId": "b52be15e-be8b-4b13-90ad-bdfd4a9b62d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: 145 mille lénages vont en bénéicier.\n",
            "\n",
            "Correct response:\n",
            ">> 145 mille ménages vont en bénéficier.\n",
            "\n",
            "Model response:\n",
            ">> 145 mille lénages vont en bénéicier.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: J'ai bin mangé ce midi.\n",
            "\n",
            "Correct response:\n",
            ">> J'ai bien mangé ce miid.\n",
            "\n",
            "Model response:\n",
            ">> J'ai bin mangé ce midi.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: Un enfant est un jeunu êre humain en corus de développement et dépendant de ses parents ou d’autres adultes.\n",
            "\n",
            "Correct response:\n",
            ">> Un enfant est un jeune être humain en cours de développement et dépendant de ses parents ou d’autres adultes.\n",
            "\n",
            "Model response:\n",
            ">> Un enfant est un jeune homme en corus de développement et départant de ses parents ou d’autres adultes.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Corrigez le texte suivant.\n",
            "\n",
            "### Input:\n",
            "grammaire: j'écrit une frase avec une faute.\n",
            "\n",
            "Correct response:\n",
            ">> j'écrit une phrase avec une faute.\n",
            "\n",
            "Model response:\n",
            ">> J'écrit une frase avec une faute.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "custom_input_data = [\n",
        "    {\n",
        "        \"instruction\": \"Corrigez le texte suivant.\",\n",
        "        \"input\": \"grammaire: 145 mille lénages vont en bénéicier.\",\n",
        "        \"output\": \"145 mille ménages vont en bénéficier.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Corrigez le texte suivant.\",\n",
        "        \"input\": \"grammaire: J'ai bin mangé ce midi.\",\n",
        "        \"output\": \"J'ai bien mangé ce midi.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Corrigez le texte suivant.\",\n",
        "        \"input\": \"grammaire: Un enfant est un jeunu êre humain en corus de développement et dépendant de ses parents ou d’autres adultes.\",\n",
        "        \"output\": \"Un enfant est un jeune être humain en cours de développement et dépendant de ses parents ou d’autres adultes.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Corrigez le texte suivant.\",\n",
        "        \"input\": \"grammaire: j'écrit une frase avec une faute.\",\n",
        "        \"output\": \"j'écrit une phrase avec une faute.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for entry in custom_input_data[:20]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC_Im8gKx_Ax"
      },
      "source": [
        "We generate the model responses on our test data set, record these responses for an evaluation of the quality of the answers made by our model with Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data[:300]), total=len(test_data[:300])):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "# Save the augmented data\n",
        "with open('augmented-correction-data-with-response.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(test_data[:300], file, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wU80u82ZL2uT",
        "outputId": "3cd9b0f3-c984-413d-d187-1772b1f28f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama not running. Launch ollama before proceeding.\")\n",
        "print(\"Ollama running:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dWki3kBGL2uT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "file_path = \"augmented-correction-data-with-response.json\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    test_data = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aOKS1X2x_Az"
      },
      "source": [
        "We send our queries to the llama3 model to get a response based on a specific prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "awaEFHyzL2uT"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(prompt, model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
        "    # Create the data payload as a dictionary\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    # Create a request object, setting the method to POST and adding necessary headers\n",
        "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww6uITbjx_Az"
      },
      "source": [
        "The quality of the responses provided is then assessed on the basis of the expected responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8ljrV4fAL2uU",
        "outputId": "e8d1d097-8d6e-4ecc-b3e9-eb6efbfb8e3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring entries: 100%|██████████| 300/300 [11:55<00:00,  2.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of scores: 300 of 300\n",
            "Average score: 60.13\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        if entry[json_key] == \"\":\n",
        "            scores.append(0)\n",
        "        else:\n",
        "            prompt = (\n",
        "                f\"Given the input `{format_input(entry)}` \"\n",
        "                f\"and correct output `{entry['output']}`, \"\n",
        "                f\"score the model response `{entry[json_key]}`\"\n",
        "                f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "                f\"Respond with the integer number only.\"\n",
        "            )\n",
        "            score = query_model(prompt, model)\n",
        "            try:\n",
        "                scores.append(int(score))\n",
        "            except ValueError:\n",
        "                print(f\"Could not convert score: {score}\")\n",
        "                continue\n",
        "\n",
        "    return scores\n",
        "\n",
        "model = \"llama3\"\n",
        "scores = generate_model_scores(test_data, \"model_response\", model=\"llama3\")\n",
        "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
        "print(f\"Average score: {sum(scores)/len(scores):.2f}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Graphic Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tkinter as tk\n",
        "from tkinter import scrolledtext\n",
        "import tiktoken\n",
        "import torch\n",
        "import tkinter as tk\n",
        "from tkinter import scrolledtext\n",
        "from previous_labs import GPTModel, load_weights_into_gpt\n",
        "\n",
        "from previous_labs import (\n",
        "    calc_loss_loader,\n",
        "    generate,\n",
        "    GPTModel,\n",
        "    load_weights_into_gpt,\n",
        "    text_to_token_ids,\n",
        "    train_model_simple,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "# Configuration for the GPT-2 model\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"drop_rate\": 0,\n",
        "    \"qkv_bias\": True,\n",
        "    \"emb_dim\": 1024,\n",
        "    \"n_layers\": 24,\n",
        "    \"n_heads\": 16\n",
        "}\n",
        "\n",
        "# Path to the fine-tuned model weights\n",
        "model_path = \"gpt2-medium355M-sft.pth\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the model\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "# Assume tiktoken is used for encoding/decoding tokens\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text\n",
        "\n",
        "def correct_text(input_text):\n",
        "    formatted_input = format_input({\n",
        "        \"instruction\": \"Corrigez le texte suivant.\",\n",
        "        \"input\": f\"grammaire: {input_text}.\",\n",
        "        \"output\": \"\"\n",
        "    })\n",
        "    token_ids = text_to_token_ids(formatted_input, tokenizer).to(device)\n",
        "    generated_token_ids = generate(\n",
        "        model=model,\n",
        "        idx=token_ids,\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(generated_token_ids, tokenizer)\n",
        "    response_text = generated_text[len(formatted_input):].replace(\"### Response:\", \"\").strip()\n",
        "    return response_text\n",
        "\n",
        "# GUI setup\n",
        "root = tk.Tk()\n",
        "root.title(\"Chat with Your LLM Model\")\n",
        "root.configure(bg='#202020')\n",
        "\n",
        "# Chat history configuration\n",
        "chat_history = scrolledtext.ScrolledText(root, state='disabled', height=20, width=70, bg='#333333', fg='white', padx=10, pady=10, font=('Arial', 12), wrap=tk.WORD)\n",
        "chat_history.grid(row=0, column=0, columnspan=2, padx=20, pady=20)\n",
        "\n",
        "chat_history.tag_configure('user', foreground='#88C0D0', background='#4C566A', justify='right', font=('Arial', 12, 'bold'))\n",
        "chat_history.tag_configure('model', foreground='#ECEFF4', background='#434C5E', justify='left', font=('Arial', 12, 'italic'))\n",
        "\n",
        "def send_message():\n",
        "    user_input = text_entry.get(\"1.0\", tk.END).strip()\n",
        "    if user_input:\n",
        "        chat_history.config(state='normal')\n",
        "        chat_history.insert(tk.END, user_input + '\\n', 'user')\n",
        "        chat_history.config(state='disabled')\n",
        "        text_entry.delete('1.0', tk.END)\n",
        "        model_response = correct_text(user_input)\n",
        "        chat_history.config(state='normal')\n",
        "        chat_history.insert(tk.END, model_response + '\\n', 'model')\n",
        "        chat_history.config(state='disabled')\n",
        "        chat_history.see(tk.END)\n",
        "\n",
        "# Bind the enter key to the send_message function\n",
        "root.bind('<Return>', send_message)\n",
        "\n",
        "# Text entry configuration\n",
        "text_entry = tk.Text(root, height=3, width=50, bg='#4C566A', fg='white', font=('Arial', 12))\n",
        "text_entry.grid(row=1, column=0, padx=20, pady=10)\n",
        "\n",
        "# Send button configuration\n",
        "send_button = tk.Button(root, text=\"Send\", command=send_message, bg='#5E81AC', fg='white', font=('Arial', 12, 'bold'))\n",
        "send_button.grid(row=1, column=1, padx=10, pady=10)\n",
        "\n",
        "root.mainloop()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "094c09b681784af69ca3ef490be44896": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11fbb6766070433abcebf79b01e39507": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12e5a69fe6f540fd8c11214090bca30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dada07c92974386b0abbf77eae5bf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca78407d76134a1e93880404f77a9594",
              "IPY_MODEL_84b11864eea44c9cad4e5994c03f748f",
              "IPY_MODEL_9029f7e1bbcc4db5ad883353320375ef"
            ],
            "layout": "IPY_MODEL_11fbb6766070433abcebf79b01e39507"
          }
        },
        "2196a9b537c84528aafc6b195ea2a697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28462e3252de40caa649850f5bc2c8fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ae846523fae43cfa21d1d4bd27a1698": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474d3c71371f4885a8adcf43e1ea8cd5",
            "max": 780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aeb1e90a77b54148896369d3f5d5681f",
            "value": 780
          }
        },
        "2f600a464b204be3abf42b523b71ba97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de2dc7bef5e46b89549e9ccc5dcec28",
            "placeholder": "​",
            "style": "IPY_MODEL_d2a7f9304300492686a8528916601d4f",
            "value": "dataset.csv: 100%"
          }
        },
        "31a172b0f05447cd9be9a3a5222b6b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2fde490b0bc4e9bbf0af7f35ce26236",
            "placeholder": "​",
            "style": "IPY_MODEL_12e5a69fe6f540fd8c11214090bca30a",
            "value": " 780/780 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "47023f7309be4c67bac489ec3cc59b45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474d3c71371f4885a8adcf43e1ea8cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b440e5088e4d0b810471309cd4e252": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5656667ec2394eb89b3eb3016b16f536": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624d1ae88acf45338fb2f7046311e7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "639b7eeb04e74fb096a6b34fdb55ed5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad4b32e67efb4638a6f83842f39b03e6",
            "max": 13231623,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e8f5c95fac64bdc8e9658e96e717850",
            "value": 13231623
          }
        },
        "65722aa38d734a9faecb5eaadffedcb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a36562da4a54569b0ce83def5a8cd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47023f7309be4c67bac489ec3cc59b45",
            "placeholder": "​",
            "style": "IPY_MODEL_6d4e5ba99abb4e73be7ba2742fa0f8e4",
            "value": " 13.2M/13.2M [00:00&lt;00:00, 40.1MB/s]"
          }
        },
        "6cb8e5ae22e94310b8a87fe9f99c2d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d4e5ba99abb4e73be7ba2742fa0f8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84b11864eea44c9cad4e5994c03f748f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5656667ec2394eb89b3eb3016b16f536",
            "max": 49112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cb8e5ae22e94310b8a87fe9f99c2d78",
            "value": 49112
          }
        },
        "8de2dc7bef5e46b89549e9ccc5dcec28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e8f5c95fac64bdc8e9658e96e717850": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9029f7e1bbcc4db5ad883353320375ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28462e3252de40caa649850f5bc2c8fa",
            "placeholder": "​",
            "style": "IPY_MODEL_a9fbab402b4e45b5b442bf877fd90cf7",
            "value": " 49112/49112 [00:00&lt;00:00, 100805.41 examples/s]"
          }
        },
        "a0c84288381f4fcc9b0c3172b224ae0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6812859e84f428d8b26f06c48ff6068": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c84288381f4fcc9b0c3172b224ae0e",
            "placeholder": "​",
            "style": "IPY_MODEL_624d1ae88acf45338fb2f7046311e7f2",
            "value": "README.md: 100%"
          }
        },
        "a9fbab402b4e45b5b442bf877fd90cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab69f6830afd49618b0eb933c0596e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6812859e84f428d8b26f06c48ff6068",
              "IPY_MODEL_2ae846523fae43cfa21d1d4bd27a1698",
              "IPY_MODEL_31a172b0f05447cd9be9a3a5222b6b15"
            ],
            "layout": "IPY_MODEL_65722aa38d734a9faecb5eaadffedcb0"
          }
        },
        "ad4b32e67efb4638a6f83842f39b03e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb1e90a77b54148896369d3f5d5681f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca78407d76134a1e93880404f77a9594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2196a9b537c84528aafc6b195ea2a697",
            "placeholder": "​",
            "style": "IPY_MODEL_094c09b681784af69ca3ef490be44896",
            "value": "Generating train split: 100%"
          }
        },
        "d2a7f9304300492686a8528916601d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2fde490b0bc4e9bbf0af7f35ce26236": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f466fd37e47f463b8589941ed24798ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f600a464b204be3abf42b523b71ba97",
              "IPY_MODEL_639b7eeb04e74fb096a6b34fdb55ed5b",
              "IPY_MODEL_6a36562da4a54569b0ce83def5a8cd41"
            ],
            "layout": "IPY_MODEL_49b440e5088e4d0b810471309cd4e252"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
